{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "206093d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "584af2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61f7cc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join(\"..\", \"src\"))\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from natsort import natsorted\n",
    "\n",
    "import scipy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.nn import functional as F\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.init import kaiming_normal_ as HeNormal\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abd33159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0+cu128\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b506b7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: cuda:0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(f'Using GPU: {device}')\n",
    "else:   \n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d3e5d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KodakDataset(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.images = natsorted(os.listdir(root))\n",
    "        self.images = [os.path.join(root, img) for img in self.images if img.endswith('.png') or img.endswith('.jpg')]\n",
    "\n",
    "    def __len__(self):        \n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        IMG_PATH = self.images[idx]\n",
    "        image = Image.open(IMG_PATH)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d729970",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv0 = nn.Conv2d(in_channels, out_channels, kernel_size=(1,1), padding=1)\n",
    "        self.conv1 = nn.Conv2d(out_channels, out_channels, kernel_size=(3,3), padding=1)\n",
    "        self.conv2 = nn.Conv2d(out_channels, in_channels, kernel_size=(1,1), padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        x = F.relu(self.conv0(x))\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        out = torch.add(residual, x)\n",
    "\n",
    "        return F.relu(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a71f13ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionModule(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(AttentionModule, self).__init__()\n",
    "        self.trunc0 = ResidualBlock(in_channels, out_channels)\n",
    "        self.trunc1 = ResidualBlock(in_channels, out_channels)\n",
    "        self.trunc2 = ResidualBlock(in_channels, out_channels)\n",
    "\n",
    "        self.atten0 = ResidualBlock(in_channels, out_channels)\n",
    "        self.atten1 = ResidualBlock(in_channels, out_channels)\n",
    "        self.atten2 = ResidualBlock(in_channels, out_channels)\n",
    "\n",
    "        self.conv0 = nn.Conv2d(in_channels, in_channels, kernel_size=(1,1), padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        trunc = self.trunc0(residual)\n",
    "        trunc = self.trunc1(trunc)\n",
    "        trunc = self.trunc2(trunc)\n",
    "\n",
    "        atten = self.atten0(residual)\n",
    "        atten = self.atten1(atten)\n",
    "        atten = self.atten2(atten)\n",
    "        atten = self.conv0(atten)\n",
    "        atten = F.sigmoid(atten)\n",
    "\n",
    "        out = torch.mul(trunc, atten)\n",
    "        out = torch.add(residual, out)\n",
    "\n",
    "        return out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Learned-Image-Compression",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
