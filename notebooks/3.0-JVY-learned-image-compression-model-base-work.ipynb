{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "206093d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "584af2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61f7cc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join(\"..\", \"src\"))\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from natsort import natsorted\n",
    "\n",
    "import scipy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.nn import functional as F\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.init import kaiming_normal_ as HeNormal\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abd33159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0+cu128\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b506b7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: cuda:0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(f'Using GPU: {device}')\n",
    "else:   \n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d3e5d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KodakDataset(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.images = natsorted(os.listdir(root))\n",
    "        self.images = [os.path.join(root, img) for img in self.images if img.endswith('.png') or img.endswith('.jpg')]\n",
    "\n",
    "    def __len__(self):        \n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        IMG_PATH = self.images[idx]\n",
    "        image = Image.open(IMG_PATH)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d729970",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv0 = nn.Conv2d(in_channels, out_channels, kernel_size=(1,1), padding=1)\n",
    "        self.conv1 = nn.Conv2d(out_channels, out_channels, kernel_size=(3,3), padding=1)\n",
    "        self.conv2 = nn.Conv2d(out_channels, in_channels, kernel_size=(1,1), padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        x = F.relu(self.conv0(x))\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        out = torch.add(residual, x)\n",
    "\n",
    "        return F.relu(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f639d2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedConvolution(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(MaskedConvolution, self).__init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a71f13ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionModule(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(AttentionModule, self).__init__()\n",
    "        self.trunc0 = ResidualBlock(in_channels, out_channels)\n",
    "        self.trunc1 = ResidualBlock(in_channels, out_channels)\n",
    "        self.trunc2 = ResidualBlock(in_channels, out_channels)\n",
    "\n",
    "        self.atten0 = ResidualBlock(in_channels, out_channels)\n",
    "        self.atten1 = ResidualBlock(in_channels, out_channels)\n",
    "        self.atten2 = ResidualBlock(in_channels, out_channels)\n",
    "\n",
    "        self.conv0 = nn.Conv2d(in_channels, in_channels, kernel_size=(1,1), padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        trunc = self.trunc0(residual)\n",
    "        trunc = self.trunc1(trunc)\n",
    "        trunc = self.trunc2(trunc)\n",
    "\n",
    "        atten = self.atten0(residual)\n",
    "        atten = self.atten1(atten)\n",
    "        atten = self.atten2(atten)\n",
    "        atten = self.conv0(atten)\n",
    "        atten = F.sigmoid(atten)\n",
    "\n",
    "        out = torch.mul(trunc, atten)\n",
    "        out = torch.add(residual, out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71490255",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GDN(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(GDN, self).__init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d3381a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnalysisTransform(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(AnalysisTransform, self).__init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed646acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperAnalysisTransform(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(HyperAnalysisTransform, self).__init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50904c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntorpyParameters(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(EntorpyParameters, self).__init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e2ff9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SynthesisTransform(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(SynthesisTransform, self).__init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12b118b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperSynthesisTransform(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(HyperSynthesisTransform, self).__init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bfb141",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Compressor(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Compressor, self).__init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c359e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decompressor(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Decompressor, self).__init__()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Learned-Image-Compression",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
